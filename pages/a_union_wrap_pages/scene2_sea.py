# app.py
"""
Streamlit app: Download insitu_subset.parquet from OBS public URL,
and visualize the selected variable as 3D bars on the map by minute.
"""

import io
import math
import requests
from datetime import timedelta

import numpy as np
import pandas as pd
import streamlit as st
import pydeck as pdk

# ---------- Configuration (modifiable in sidebar) ----------
DEFAULT_PQ_URL = "https://gaoyuan-49d0.obs.cn-north-4.myhuaweicloud.com/%E6%B5%B7%E6%B4%8B%E7%89%A7%E5%9C%BA-%E6%96%87%E6%9C%AC%2B%E6%97%B6%E5%BA%8F/insitu_subset.parquet"

# ---------- Helper functions ----------
@st.cache_data(ttl=3600)
def load_parquet_from_url(url: str) -> pd.DataFrame:
    """Download parquet file from URL and return as pandas.DataFrame (exceptions will be shown on the page)."""
    r = requests.get(url, timeout=120)
    r.raise_for_status()
    bio = io.BytesIO(r.content)
    # Use pandas directly, depends on pyarrow or fastparquet
    df = pd.read_parquet(bio)
    return df

def prepare_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Clean and add columns for easier visualization."""
    df = df.copy()
    # time -> datetime (UTC)
    df["time"] = pd.to_datetime(df["time"], utc=True, errors="coerce")
    # Tolerant handling of longitude/latitude column names (your data has longitude / latitude)
    if "longitude" not in df.columns or "latitude" not in df.columns:
        raise KeyError("Missing 'longitude' or 'latitude' column.")
    df["longitude"] = pd.to_numeric(df["longitude"], errors="coerce")
    df["latitude"] = pd.to_numeric(df["latitude"], errors="coerce")
    # value -> numeric
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    # Small-sample filtering: drop rows with NaN in lon/lat, NaT in time, or NaN in value
    df = df.dropna(subset=["longitude", "latitude", "time", "value"])
    # Align by minute for frame selection
    df["minute"] = df["time"].dt.floor("min")
    return df

def aggregate_for_minute(df_var: pd.DataFrame, minute_ts: pd.Timestamp) -> pd.DataFrame:
    """
    Aggregate data for the given minute_ts (timezone-aware pandas.Timestamp) by platform_id + lon/lat:
    Returns a DataFrame with columns: platform_id, longitude, latitude, value (mean), count, depth (mean).
    """
    dfm = df_var[df_var["minute"] == minute_ts]
    if dfm.empty:
        return pd.DataFrame(columns=["platform_id","longitude","latitude","value","count","depth"])
    grp = dfm.groupby(["platform_id", "longitude", "latitude"], as_index=False).agg(
        value=("value", "mean"),
        count=("value", "count"),
        depth=("depth", "mean")
    )
    return grp

def compute_height_and_color(df_plot: pd.DataFrame, v_low=None, v_high=None, target_p99_height=1000.0):
    """
    Compute bar height (meters) and RGBA color column (list).
    Mapping strategy:
     - Linearly map value in v_low..v_high to 0..target_p99_height (v_high defaults to 99% quantile)
     - Color interpolated linearly from blue (low) to red (high)
    """
    if df_plot.empty:
        return df_plot
    vals = df_plot["value"].astype(float)
    if v_low is None:
        v_low = float(vals.quantile(0.01))
    if v_high is None:
        v_high = float(vals.quantile(0.99))
    # Prevent v_high == v_low
    if v_high <= v_low:
        v_high = v_low + 1.0
    # Normalize and compute height
    t = ((vals - v_low) / (v_high - v_low)).clip(0.0, 1.0)
    df_plot["height"] = (t * target_p99_height).astype(float)
    # Linear interpolation of color (blue->red)
    def lerp(u):
        r = int(255 * u)
        g = int(50 + 150 * (1 - abs(u - 0.5) * 2))  # keep a bit of green for mid values
        b = int(255 * (1 - u))
        return [r, g, b, 180]
    df_plot["color"] = [lerp(u) for u in t]
    return df_plot
def run_scene2():
  # ---------- Page layout ----------
  st.set_page_config(page_title="INSITU Parquet å˜é‡åœ°å›¾æŸ±çŠ¶å›¾", layout="wide")
  st.title("ğŸ“¦ INSITU Parquet â†’ æŒ‰åˆ†é’Ÿ 3D æŸ±çŠ¶å˜é‡å±•ç¤º")

  # Sidebar: URL / load settings / filtering
  st.sidebar.header("æ•°æ®æºä¸ç­›é€‰")
  pq_url = st.sidebar.text_input("Parquet æ–‡ä»¶ URLï¼ˆOBSï¼‰", value=DEFAULT_PQ_URL)
  load_btn = st.sidebar.button("é‡æ–°åŠ è½½æ•°æ®")

  # Try loading (cached)
  try:
      with st.spinner("ä» URL åŠ è½½ Parquet æ–‡ä»¶..."):
          df_raw = load_parquet_from_url(pq_url)
  except Exception as e:
      st.error(f"åŠ è½½ parquet å¤±è´¥ï¼š{e}")
      st.stop()

  # Show basic info
  st.sidebar.markdown(f"**æ•°æ®å¤§å°:** {df_raw.shape[0]} è¡Œ Ã— {df_raw.shape[1]} åˆ—")
  st.expander("æŸ¥çœ‹åŸå§‹è¡¨å¤´ä¸å‰ 5 è¡Œ", expanded=False).write(df_raw.head())

  # Preprocessing
  try:
      df = prepare_dataframe(df_raw)
  except Exception as e:
      st.error(f"é¢„å¤„ç†å¤±è´¥ï¼š{e}")
      st.stop()

  # Variable selection
  vars_available = sorted(df["variable"].dropna().unique().astype(str))
  if not vars_available:
      st.error("æ•°æ®ä¸­æœªæ‰¾åˆ°å¯ç”¨çš„ 'variable' å€¼ã€‚")
      st.stop()

  variable = st.sidebar.selectbox("é€‰æ‹© variable", vars_available, index=0)
  df_var = df[df["variable"].astype(str) == variable].copy()
  st.sidebar.markdown(f"**é€‰ä¸­å˜é‡è¡Œæ•°:** {len(df_var)}")

  # value_qc filter (if exists)
  if "value_qc" in df_var.columns:
      qcs = sorted(df_var["value_qc"].dropna().unique().tolist())
      qc_sel = st.sidebar.multiselect("value_qcï¼ˆè¿‡æ»¤ï¼‰", qcs, default=qcs)
      if qc_sel:
          df_var = df_var[df_var["value_qc"].isin(qc_sel)]
  else:
      st.sidebar.caption("æ•°æ®ä¸­æ—  value_qc åˆ—ï¼Œè·³è¿‡ QC è¿‡æ»¤ã€‚")

  # Time frame selection (by minute)
  minutes_sorted = sorted(df_var["minute"].dropna().unique())
  if not minutes_sorted:
      st.warning("æ‰€é€‰å˜é‡åœ¨æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨æ—¶é—´ç‚¹ã€‚")
      st.stop()

  # Select time frame index in sidebar (shown as readable time)
  min_idx = 0
  max_idx = len(minutes_sorted) - 1
  frame_idx = st.sidebar.slider(
      "é€‰æ‹©æ—¶é—´å¸§ï¼ˆæŒ‰åˆ†é’Ÿï¼‰",
      min_value=min_idx,
      max_value=max_idx,
      value=min_idx,
      step=1,
      format="%d"  # slider internally still returns index
  )
  selected_minute = pd.to_datetime(minutes_sorted[frame_idx])
  st.sidebar.markdown(f"**å½“å‰åˆ†é’Ÿï¼š** {selected_minute} (UTC)")

  # Optional: time window aggregation (minutes)
  agg_minutes = st.sidebar.number_input("èšåˆçª—å£ï¼ˆåˆ†é’Ÿï¼Œä¸­å¿ƒåŒ–äºæ‰€é€‰åˆ†é’Ÿï¼›0 å³ä»…è¯¥åˆ†é’Ÿï¼‰", min_value=0, max_value=60, value=0, step=1)

  # Filter time range according to aggregation window
  if agg_minutes and agg_minutes > 0:
      half = int(agg_minutes // 2)
      start_ts = selected_minute - pd.Timedelta(minutes=half)
      end_ts = selected_minute + pd.Timedelta(minutes=half)
      df_window = df_var[(df_var["time"] >= start_ts) & (df_var["time"] <= end_ts)]
      st.write(f"èšåˆæ—¶é—´èŒƒå›´ï¼š{start_ts} â€” {end_ts}ï¼Œè¡Œæ•° {len(df_window)}")
      # Take mean per platform
      df_group = df_window.groupby(["platform_id", "longitude", "latitude"], as_index=False).agg(
          value=("value", "mean"), count=("value", "count"), depth=("depth", "mean")
      )
  else:
      df_group = aggregate_for_minute(df_var, selected_minute)

  if df_group.empty:
      st.warning("å½“å‰å¸§æ²¡æœ‰æ•°æ®ï¼Œå°è¯•åˆ‡æ¢åˆ°å…¶å®ƒæ—¶é—´å¸§æˆ–æ”¾å®½æ—¶é—´çª—å£ã€‚")
      st.stop()

  # Compute height and color
  df_plot = compute_height_and_color(df_group, target_p99_height=1000.0)

  # Compute map center and radius
  center_lat = float(df_plot["latitude"].mean())
  center_lon = float(df_plot["longitude"].mean())

  # Adaptive radius based on lat/lon span (avoid all bars overlapping)
  lat_span = df_plot["latitude"].max() - df_plot["latitude"].min()
  lon_span = df_plot["longitude"].max() - df_plot["longitude"].min()
  max_span_deg = max(lat_span, lon_span, 0.01)
  # 1 deg ~ 111km (approx.)
  radius_m = 40000

  # Build pydeck Layer
  layer = pdk.Layer(
      "ColumnLayer",
      data=df_plot,
      get_position=["longitude", "latitude"],
      get_elevation="height",
      elevation_scale=500.0,
      radius=radius_m,
      get_fill_color="color",
      pickable=True,
      auto_highlight=True,
  )

  view_state = pdk.ViewState(latitude=center_lat, longitude=center_lon, zoom=4, pitch=45)

  tooltip = {
      "html": "<b>{platform_id}</b><br/>value: {value:.3f}<br/>count: {count}<br/>lat: {latitude}, lon: {longitude}<br/>depth: {depth}",
      "style": {"color": "white"},
  }

  deck = pdk.Deck(layers=[layer], initial_view_state=view_state, tooltip=tooltip, map_style=None)

  st.subheader(f"åœ°å›¾ï¼šå˜é‡ {variable}ï¼ˆæ—¶é—´ï¼š{selected_minute} UTCï¼‰")
  st.pydeck_chart(deck, use_container_width=True)

  # Show table and stats on the right or below
  with st.expander("å½“å‰å¸§æ•°æ®è¡¨æ ¼ï¼ˆèšåˆåï¼‰", expanded=True):
      st.dataframe(df_plot.sort_values("value", ascending=False).reset_index(drop=True))

  # Simple statistics & distribution
  col1, col2 = st.columns([2, 1])
  with col1:
      st.metric("ç«™ç‚¹æ•°é‡ï¼ˆå½“å‰å¸§ï¼‰", f"{len(df_plot)}")
      st.write("å€¼ç»Ÿè®¡ï¼ˆåŸå§‹å‡å€¼ï¼‰")
      desc = df_plot["value"].describe().to_frame().T
      st.table(desc)
  with col2:
      st.write("å€¼åˆ†å¸ƒç›´æ–¹å›¾")
      st.bar_chart(df_plot["value"].dropna())

  st.caption("è¯´æ˜ï¼šæŸ±é«˜ä¸º value çš„å½’ä¸€åŒ–é«˜åº¦ï¼ˆ99% æ˜ å°„åˆ° ~1000mï¼‰ã€‚è‹¥ä½ å¸Œæœ›ç”¨åŸå§‹ç‰©ç†å•ä½ç›´æ¥æ˜ å°„é«˜åº¦ï¼Œè¯·åœ¨ä»£ç ä¸­è°ƒæ•´ compute_height_and_color çš„æ˜ å°„ç­–ç•¥ã€‚")

  # Export current aggregated table as CSV
  csv_bytes = df_plot.to_csv(index=False).encode("utf-8")
  st.download_button("ä¸‹è½½å½“å‰å¸§èšåˆæ•°æ®ï¼ˆCSVï¼‰", csv_bytes, file_name=f"{variable}_{selected_minute.strftime('%Y%m%dT%H%M')}.csv")